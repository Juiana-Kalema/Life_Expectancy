{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f06938",
   "metadata": {},
   "source": [
    "# Life Expectancy Data Science Project\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "### Introduction\n",
    "This analysis explores a life expectancy dataset, aiming to uncover factors affecting life expectancy across countries over time. We'll handle missing values, engineer features, perform exploratory analysis, visualize patterns, and build a regression model to predict life expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505a440",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "- Understand the structure and quality of the dataset\n",
    "- Identify key features affecting life expectancy\n",
    "- Handle missing data appropriately\n",
    "- Engineer new features to improve prediction\n",
    "- Visualize relationships and trends\n",
    "- Build a regression model to predict life expectancy\n",
    "- Evaluate model performance using cross-validation\n",
    "- Derive actionable insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1637f4",
   "metadata": {},
   "source": [
    "### Task 1: Explore Dataset and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy.stats.mstats import winsorize\n",
    "import re\n",
    "from scipy.stats import median_abs_deviation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Life_Expectancy_Data.csv')\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d25cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column in df.columns:\n",
    "    # Remove leading/trailing spaces and compress multiple spaces into single spaces\n",
    "    cleaned_column = re.sub(r'\\s+', ' ', column.strip())\n",
    "    df.rename(columns={column: cleaned_column}, inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv(\"Cleaned_Life_Expectancy.csv\", index=False)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4375b9e",
   "metadata": {},
   "source": [
    "#### Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns in the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "#Description of the dataset transposed\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find total of duplicated values\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique countries from the 'Country' column\n",
    "number_of_countries = df['Country'].nunique()\n",
    "\n",
    "# Print the number of unique countries\n",
    "print(f\"The total number of unique countries in the dataset is: {number_of_countries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dae62",
   "metadata": {},
   "source": [
    "### Task 2: Handle Missing Data and Justify Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ebf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if any column has NaN\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1933df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if any row has NaN\n",
    "df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if all values in a column are NaN\n",
    "df.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if all values in a row are NaN\n",
    "df.isnull().all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = (df.isnull().sum() / len(df))*100\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25509de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.DataFrame({'Missing Values': null_values, 'Percent Missing': null_percentage})\n",
    "missing_df[missing_df['Missing Values'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545100cd",
   "metadata": {},
   "source": [
    "### Advanced mechanisms to handle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d7ae6",
   "metadata": {},
   "source": [
    "#### Outlier detection\n",
    "1. Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3abe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Initialize tracker ===\n",
    "outlier_indices_per_column = {col: set() for col in df.select_dtypes(include='number').columns}\n",
    "\n",
    "# === Z-Score function ===\n",
    "def detect_outliers(series, threshold=3.5):\n",
    "    median = series.median()\n",
    "    mad = median_abs_deviation(series, scale='normal')  # scaled to be comparable to std\n",
    "    if mad == 0:\n",
    "        return pd.Series([False] * len(series), index=series.index)\n",
    "    z_scores = 0.6745 * (series - median) / mad\n",
    "    return abs(z_scores) > threshold\n",
    "\n",
    "# === Process per country ===\n",
    "for country, group in df.groupby('Country'):\n",
    "    for col in df.select_dtypes(include='number').columns:\n",
    "        is_outlier = detect_outliers(group[col])\n",
    "        outlier_indices_per_column[col].update(group[is_outlier].index)\n",
    "\n",
    "# === Build summary table ===\n",
    "summary = []\n",
    "for col, indices in outlier_indices_per_column.items():\n",
    "    count = len(indices)\n",
    "    summary.append({\n",
    "        'Column': col,\n",
    "        'Outlier Count': count,\n",
    "        'Percentage': round((count / len(df)) * 100, 2)\n",
    "    })\n",
    "\n",
    "# === Create DataFrame and show results ===\n",
    "outlier_summary = pd.DataFrame(summary).sort_values(by='Outlier Count', ascending=False)\n",
    "\n",
    "print(\"Outlier Detection Summary (Z-Score per Country, Unique Rows Only)\")\n",
    "print(\"=\" * 70)\n",
    "print(outlier_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a97ce",
   "metadata": {},
   "source": [
    "2. Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === First feature group ===\n",
    "features_1 = ['Polio', 'Diphtheria', 'Income composition of resources',\n",
    "              'HIV/AIDS', 'thinness 1-19 years', 'thinness 5-9 years']\n",
    "\n",
    "# === Second feature group ===\n",
    "features_2 = ['Measles', 'GDP', 'percentage expenditure', 'Adult Mortality', 'under-five deaths', 'Total expenditure']\n",
    "\n",
    "features_3 = ['Population', 'Alcohol', 'Schooling', 'BMI', 'Life expectancy', 'Hepatitis B']\n",
    "\n",
    "# === Prepare melted data for both groups ===\n",
    "def melt_and_tag_outliers(df, features):\n",
    "    melted = df[['Country'] + features].melt(id_vars='Country', var_name='Feature', value_name='Value')\n",
    "\n",
    "    def detect_and_tag_outliers(group):\n",
    "        q1 = group['Value'].quantile(0.25)\n",
    "        q3 = group['Value'].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        group['Outlier'] = (group['Value'] < lower) | (group['Value'] > upper)\n",
    "        return group\n",
    "\n",
    "    tagged = melted.groupby(['Country', 'Feature'], group_keys=False).apply(detect_and_tag_outliers)\n",
    "    return tagged\n",
    "\n",
    "df_tagged_1 = melt_and_tag_outliers(df, features_1)\n",
    "df_tagged_2 = melt_and_tag_outliers(df, features_2)\n",
    "df_tagged_3 = melt_and_tag_outliers(df, features_3)\n",
    "\n",
    "# === Create subplots ===\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, figsize=(14, 30))  # reduce figure height\n",
    "\n",
    "\n",
    "# --- Plot 1 ---\n",
    "sns.boxplot(data=df_tagged_1, x='Feature', y='Value', showfliers=False, ax=ax1)\n",
    "sns.stripplot(\n",
    "    data=df_tagged_1[df_tagged_1['Outlier']],\n",
    "    x='Feature',\n",
    "    y='Value',\n",
    "    hue='Country',\n",
    "    dodge=True,\n",
    "    jitter=True,\n",
    "    marker='o',\n",
    "    alpha=0.6,\n",
    "    linewidth=0.5,\n",
    "    edgecolor='gray',\n",
    "    palette='tab20',\n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set_title(\"Group 1: Country-Based Outliers (Polio, Diphtheria, etc.)\")\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend_.remove()\n",
    "\n",
    "\n",
    "# --- Plot 2 ---\n",
    "sns.boxplot(data=df_tagged_2, x='Feature', y='Value', showfliers=False, ax=ax2)\n",
    "sns.stripplot(\n",
    "    data=df_tagged_2[df_tagged_2['Outlier']],\n",
    "    x='Feature',\n",
    "    y='Value',\n",
    "    hue='Country',\n",
    "    dodge=True,\n",
    "    jitter=True,\n",
    "    marker='o',\n",
    "    alpha=0.6,\n",
    "    linewidth=0.5,\n",
    "    edgecolor='gray',\n",
    "    palette='tab20',\n",
    "    ax=ax2\n",
    ")\n",
    "ax2.set_title(\"Group 2: Country-Based Outliers (Measles, GDP, etc.)\")\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax2.legend_.remove()\n",
    "\n",
    "# --- Plot 3 ---\n",
    "sns.boxplot(data=df_tagged_3, x='Feature', y='Value', showfliers=False, ax=ax3)\n",
    "sns.stripplot(\n",
    "    data=df_tagged_3[df_tagged_3['Outlier']],\n",
    "    x='Feature',\n",
    "    y='Value',\n",
    "    hue='Country',\n",
    "    dodge=True,\n",
    "    jitter=True,\n",
    "    marker='o',\n",
    "    alpha=0.6,\n",
    "    linewidth=0.5,\n",
    "    edgecolor='gray',\n",
    "    palette='tab20',\n",
    "    ax=ax3\n",
    ")\n",
    "ax3.set_title(\"Group 3: Country-Based Outliers (Population, Alcohol, etc.)\")\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.legend_.remove()\n",
    "\n",
    "\n",
    "# === Add legend outside the full figure ===\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title='Country', bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6dd44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.select_dtypes(include='number').corr(), cmap='coolwarm', annot=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f1923",
   "metadata": {},
   "source": [
    "### Task 3: Apply Chosen Method and Evaluate\n",
    "\n",
    "### Implementation of the chosen methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will use percentile-based capping due to skewness\n",
    "skewed_features = ['Adult Mortality']\n",
    "# These will use IQR capping\n",
    "iqr_features = ['Polio', 'Diphtheria', 'Hepatitis B',\n",
    "                'Total expenditure']\n",
    "# These will use log transformation\n",
    "log_transform_features = ['Measles', 'Population', 'Alcohol', 'percentage expenditure']\n",
    "\n",
    "# Features to process (but we'll keep all other features unchanged)\n",
    "features_to_process = skewed_features + iqr_features + log_transform_features \n",
    "\n",
    "# === Impute missing values using country-wise median for ALL features ===\n",
    "print(\"ðŸ”§ Imputing missing values with country-wise median...\")\n",
    "# Get all numeric columns except Country and Year\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Remove Country and Year if they exist in numeric columns\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['Country', 'Year']]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        df[col] = df.groupby('Country')[col].transform(lambda x: x.fillna(x.median()))\n",
    "        if df[col].isnull().any():\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "print(\"Imputation complete.\")\n",
    "\n",
    "# === Helper Functions ===\n",
    "\n",
    "def percentile_cap_grouped(df, col, lower=0.01, upper=0.99):\n",
    "    \"\"\"Apply percentile capping per country.\"\"\"\n",
    "    def cap(x):\n",
    "        return x.clip(lower=x.quantile(lower), upper=x.quantile(upper))\n",
    "    return df.groupby(\"Country\")[col].transform(cap)\n",
    "\n",
    "def iqr_cap_grouped(df, col):\n",
    "    \"\"\"Apply IQR capping per country.\"\"\"\n",
    "    def cap(x):\n",
    "        q1 = x.quantile(0.25)\n",
    "        q3 = x.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        if iqr == 0 or x.isnull().all():\n",
    "            return x\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        return x.clip(lower, upper)\n",
    "    return df.groupby(\"Country\")[col].transform(cap)\n",
    "\n",
    "def apply_log_transform_safely(x):\n",
    "    \"\"\"Log transform safely, avoiding log(0).\"\"\"\n",
    "    return np.log1p(x.clip(lower=0))\n",
    "\n",
    "# === Apply transformations ONLY to specified features ===\n",
    "print(\"\\nApplying transformations and tracking changes...\")\n",
    "df_cleaned = df.copy()\n",
    "changes_summary = {}\n",
    "\n",
    "\n",
    "\n",
    "# 2. IQR Capping â†’ other features\n",
    "for col in iqr_features:\n",
    "    if col in df_cleaned.columns:\n",
    "        before = df_cleaned[col].copy()\n",
    "        df_cleaned[col] = iqr_cap_grouped(df_cleaned, col)\n",
    "        changes_summary[col] = (df_cleaned[col] != before).sum()\n",
    "        print(f\"âœ” IQR Capped â†’ {col}: {changes_summary[col]} values modified\")\n",
    "\n",
    "# 3. Log Transform â†’ log_transform_features\n",
    "for col in log_transform_features:\n",
    "    if col in df_cleaned.columns:\n",
    "        before = df_cleaned[col].copy()\n",
    "        df_cleaned[col] = apply_log_transform_safely(df_cleaned[col])\n",
    "        changes_summary[col] = (df_cleaned[col] != before).sum()\n",
    "        print(f\"âœ” Log Transformed â†’ {col}: {changes_summary[col]} values modified\")\n",
    "\n",
    "# === Save cleaned dataset with ALL original features ===\n",
    "# Keep all columns from the original dataset\n",
    "df_final = df_cleaned.copy()\n",
    "df_final.to_csv(\"Cleaned_Life_Expectancy.csv\", index=False)\n",
    "\n",
    "# === Summary ===\n",
    "print(\"Final Summary of Outlier Handling:\")\n",
    "for col, count in changes_summary.items():\n",
    "    if col in iqr_features:\n",
    "        method = \"IQR Capped\"\n",
    "    else:\n",
    "        method = \"Log Transformed\"\n",
    "    print(f\"âœ” {method} â†’ {col}: {count} values modified\")\n",
    "\n",
    "print(f\"Dataset Info:\")\n",
    "print(f\"Total columns in cleaned dataset: {len(df_final.columns)}\")\n",
    "print(f\"Columns processed: {len(features_to_process)}\")\n",
    "print(f\"Columns unchanged: {len(df_final.columns) - len(features_to_process)}\")\n",
    "\n",
    "print(\"Cleaned dataset saved as: Cleaned_Life_Expectancy.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values for BMI separately\n",
    "df = pd.read_csv('Cleaned_Life_Expectancy.csv')\n",
    "# === Step 1: Identify and mask biologically implausible BMI values ===\n",
    "# Values outside a reasonable range for a national average are considered invalid.\n",
    "invalid_bmi_mask = (df['BMI'] < 15) | (df['BMI'] > 40)\n",
    "num_bmi_replaced = invalid_bmi_mask.sum()\n",
    "\n",
    "print(f\"ðŸ”§ Identified {num_bmi_replaced} invalid BMI values to be imputed.\")\n",
    "\n",
    "# Replace these invalid values with NaN so they can be imputed\n",
    "df['BMI'] = df['BMI'].mask(invalid_bmi_mask, np.nan)\n",
    "\n",
    "\n",
    "# === Step 2: Impute missing BMI values using MICE ===\n",
    "# MICE will predict missing BMI values based ONLY on Life expectancy, as requested.\n",
    "impute_cols = ['Life expectancy', 'BMI']\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "\n",
    "# The imputer will predict the missing 'BMI' values based on 'Life expectancy'.\n",
    "# The result is assigned back to the correct columns in the main DataFrame.\n",
    "df[impute_cols] = imputer.fit_transform(df[impute_cols])\n",
    "print(\"BMI values imputed successfully using MICE.\")\n",
    "\n",
    "\n",
    "# === Step 3: Save the ENTIRE cleaned dataset ===\n",
    "# This saves the full DataFrame with all original columns, plus the cleaned BMI column.\n",
    "df.to_csv('Cleaned_Life_Expectancy.csv', index=False)\n",
    "print(\"Full dataset with cleaned BMI saved to 'Cleaned_Life_Expectancy.csv'\")\n",
    "\n",
    "\n",
    "# --- Output Summary ---\n",
    "print(\"\\nFinal Cleaned Dataset (Sample):\")\n",
    "# Displaying more columns to confirm they were all kept\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values for GDP separately\n",
    "df = pd.read_csv('Cleaned_Life_Expectancy.csv')\n",
    "# --- Step 0: Initial State ---\n",
    "print(\"\\n--- Initial State of GDP Column ---\")\n",
    "initial_missing_gdp = df['GDP'].isnull().sum()\n",
    "print(f\"Number of missing GDP values initially: {initial_missing_gdp}\")\n",
    "\n",
    "# --- Step 1: Detect Outliers on a Per-Country Basis ---\n",
    "print(\"\\n--- Step 1: Detecting Outliers for Each Country Individually ---\")\n",
    "\n",
    "def get_country_upper_bound(series):\n",
    "    \"\"\"Calculates the upper outlier bound for a pandas Series.\"\"\"\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - series.quantile(0.25)\n",
    "    return q3 + 1.5 * iqr\n",
    "\n",
    "def get_country_lower_bound(series):\n",
    "    \"\"\"Calculates the lower outlier bound, enforcing a domain-specific minimum.\"\"\"\n",
    "    q1 = series.quantile(0.25)\n",
    "    iqr = series.quantile(0.75) - q1\n",
    "    iqr_lower_bound = q1 - 1.5 * iqr\n",
    "    # Set an absolute minimum plausible value for GDP per capita\n",
    "    domain_lower_bound = 100.0\n",
    "    # Use the larger of the two lower bounds to be less restrictive, but never go below our absolute minimum.\n",
    "    return max(iqr_lower_bound, domain_lower_bound)\n",
    "\n",
    "# Apply outlier bound calculations for each country\n",
    "country_upper_bounds = df.groupby('Country')['GDP'].transform(get_country_upper_bound)\n",
    "country_lower_bounds = df.groupby('Country')['GDP'].transform(get_country_lower_bound)\n",
    "\n",
    "# Create a boolean mask to identify rows with outlier GDP values\n",
    "outlier_mask = (df['GDP'] < country_lower_bounds) | (df['GDP'] > country_upper_bounds)\n",
    "outliers = df[outlier_mask]\n",
    "\n",
    "print(f\"Number of GDP outliers detected across all countries: {len(outliers)}\")\n",
    "if not outliers.empty:\n",
    "    print(\"Sample of detected outliers:\")\n",
    "    print(outliers[['Country', 'Year', 'GDP']].head())\n",
    "\n",
    "# --- Step 2: Mark Outliers as NaN ---\n",
    "print(\"\\n--- Step 2: Marking Outliers as Invalid (NaN) ---\")\n",
    "df.loc[outlier_mask, 'GDP'] = np.nan\n",
    "total_missing_after_marking = df['GDP'].isnull().sum()\n",
    "print(f\"Total GDP values now missing (NaN): {total_missing_after_marking}\")\n",
    "\n",
    "# --- Step 3: Impute with Country-Specific Mean ---\n",
    "print(\"\\n--- Step 3: Imputing Missing/Invalid Values ---\")\n",
    "# Calculate the mean of valid GDPs for each country\n",
    "country_gdp_mean = df.groupby('Country')['GDP'].transform('mean')\n",
    "# Fill NaN values with the respective country's mean\n",
    "df['GDP'].fillna(country_gdp_mean, inplace=True)\n",
    "\n",
    "# Fallback to global mean if any country had all its values as NaN\n",
    "global_gdp_mean = df['GDP'].mean()\n",
    "df['GDP'].fillna(global_gdp_mean, inplace=True)\n",
    "print(\"GDP values imputed successfully.\")\n",
    "\n",
    "# --- Step 4: Save the ENTIRE cleaned dataset ---\n",
    "# This saves the full DataFrame with all original columns, plus the cleaned GDP column.\n",
    "df.to_csv(\"Cleaned_Life_Expectancy.csv\", index=False)\n",
    "print(\"Full dataset with cleaned GDP saved to 'Cleaned_Life_Expectancy.csv'\")\n",
    "\n",
    "# --- Output Summary ---\n",
    "print(\"\\nFinal Cleaned Dataset (Sample):\")\n",
    "# Displaying the head of the full dataframe to confirm all columns were kept\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1361cf",
   "metadata": {},
   "source": [
    "### Box plot to inspect cleaned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === First feature group ===\n",
    "features_1 = ['Polio', 'Diphtheria', 'HIV/AIDS', 'Measles', 'GDP', 'percentage expenditure']\n",
    "\n",
    "# === Second feature group ===\n",
    "features_2 = ['Total expenditure', 'Adult Mortality', 'Alcohol', 'Population']\n",
    "\n",
    "# === Prepare melted data for both groups ===\n",
    "def melt_and_tag_outliers(df, features):\n",
    "    melted = df[['Country'] + features].melt(id_vars='Country', var_name='Feature', value_name='Value')\n",
    "\n",
    "    def detect_and_tag_outliers(group):\n",
    "        q1 = group['Value'].quantile(0.25)\n",
    "        q3 = group['Value'].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        group['Outlier'] = (group['Value'] < lower) | (group['Value'] > upper)\n",
    "        return group\n",
    "\n",
    "    tagged = melted.groupby(['Country', 'Feature'], group_keys=False).apply(detect_and_tag_outliers)\n",
    "    return tagged\n",
    "\n",
    "df_tagged_1 = melt_and_tag_outliers(df, features_1)\n",
    "df_tagged_2 = melt_and_tag_outliers(df, features_2)\n",
    "\n",
    "# === Create subplots ===\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(14, 30))  # reduce figure height\n",
    "\n",
    "\n",
    "# --- Plot 1 ---\n",
    "sns.boxplot(data=df_tagged_1, x='Feature', y='Value', showfliers=False, ax=ax1)\n",
    "sns.stripplot(\n",
    "    data=df_tagged_1[df_tagged_1['Outlier']],\n",
    "    x='Feature',\n",
    "    y='Value',\n",
    "    hue='Country',\n",
    "    dodge=True,\n",
    "    jitter=True,\n",
    "    marker='o',\n",
    "    alpha=0.6,\n",
    "    linewidth=0.5,\n",
    "    edgecolor='gray',\n",
    "    palette='tab20',\n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set_title(\"Group 1: Country-Based Outliers (Polio, Diphtheria, etc.)\")\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend_.remove()\n",
    "\n",
    "\n",
    "# --- Plot 2 ---\n",
    "sns.boxplot(data=df_tagged_2, x='Feature', y='Value', showfliers=False, ax=ax2)\n",
    "sns.stripplot(\n",
    "    data=df_tagged_2[df_tagged_2['Outlier']],\n",
    "    x='Feature',\n",
    "    y='Value',\n",
    "    hue='Country',\n",
    "    dodge=True,\n",
    "    jitter=True,\n",
    "    marker='o',\n",
    "    alpha=0.6,\n",
    "    linewidth=0.5,\n",
    "    edgecolor='gray',\n",
    "    palette='tab20',\n",
    "    ax=ax2\n",
    ")\n",
    "ax2.set_title(\"Group 2: Country-Based Outliers (Measles, GDP, etc.)\")\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax2.legend_.remove()\n",
    "\n",
    "# === Add legend outside the full figure ===\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title='Country', bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87d6d2",
   "metadata": {},
   "source": [
    "### Task 4: Identify Potential Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a759bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor to measure multicollinearity\n",
    "# High VIF (> 10): The feature is highly redundant â€” itâ€™s linearly predictable from other features.\n",
    "#Low VIF (< 5): Low multicollinearity â€” the feature gives unique information.\n",
    "\n",
    "\n",
    "X = df_final.select_dtypes(include=[float, int]).drop(columns=['Life expectancy'])\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data.sort_values('VIF', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'Adult Mortality',\n",
    "    'Alcohol',\n",
    "    'Total expenditure',\n",
    "    'Measles',\n",
    "    'HIV/AIDS',\n",
    "    'GDP',\n",
    "    'BMI'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080fd711",
   "metadata": {},
   "source": [
    "###  Task 5: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f67f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Immunization Score'] = df_final[['Polio', 'Diphtheria', 'Hepatitis B']].mean(axis=1)\n",
    "df_final['HIV Impact Score'] = df_final['HIV/AIDS'] * df_final['Adult Mortality']\n",
    "df_final['Health Investment'] = df_final['percentage expenditure'] * df_final['GDP']\n",
    "df_final['Healthcare Access Ratio'] = df_final['Total expenditure'] / (df_final['GDP'] + 1e-5)\n",
    "df_final['Mortality Rate Ratio'] = df_final['Adult Mortality'] / (df_final['Life expectancy'] + 1e-5)\n",
    "df_final['Schooling vs Alcohol'] = df_final['Schooling'] / (df_final['Alcohol'] + 1e-5)\n",
    "df_final['Resource Efficiency'] = df_final['Income composition of resources'] * df_final['Schooling']\n",
    "df_final['Health Spending Per Capita'] = df_final['Total expenditure'] / (df_final['Population'] + 1e-5)\n",
    "df_final['Population GDP Ratio'] = df_final['Population'] / (df_final['GDP'] + 1e-5)\n",
    "df_final['BMI Deviation'] = abs(df_final['BMI'] - 22.5)\n",
    "df_final['Thinness Ratio'] = df_final['thinness 1-19 years'] / (df_final['thinness 5-9 years'] + 1e-5)\n",
    "df_final['Healthcare Access Score'] = df_final['Immunization Score'] * df_final['Health Investment']\n",
    "df_final['GDP per Health $'] = df_final['GDP'] / (df_final['Total expenditure'] + 1e-5)\n",
    "df_final['Child Vulnerability Index'] = 0.6 * df_final['HIV/AIDS'] + 0.4 * (df_final['under-five deaths'] + df_final['infant deaths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08a9de",
   "metadata": {},
   "source": [
    "### Task 6: Impact of New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480caf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features before engineering\n",
    "X_base = df_final[selected_features]\n",
    "y = df_final['Life expectancy']\n",
    "\n",
    "# Cross-validation with original features\n",
    "base_model = LinearRegression()\n",
    "base_score = cross_val_score(base_model, X_base, y, cv=5, scoring='r2').mean()\n",
    "\n",
    "# Features after adding engineered ones\n",
    "engineered_features = ['Immunization Score', 'Health Investment', 'Healthcare Access Ratio', \n",
    "                       'Mortality Rate Ratio', 'Schooling vs Alcohol', \n",
    "                       'Resource Efficiency', 'Health Spending Per Capita', 'Population GDP Ratio', 'BMI Deviation', 'Thinness Ratio',\n",
    "                       'Healthcare Access Score', 'GDP per Health $', 'HIV Impact Score']\n",
    "X_eng = df_final[selected_features + engineered_features]\n",
    "\n",
    "# Cross-validation with engineered features\n",
    "eng_model = LinearRegression()\n",
    "eng_score = cross_val_score(eng_model, X_eng, y, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(f\"RÂ² (Base Features Only): {base_score:.4f}\")\n",
    "print(f\"RÂ² (With Engineered Features): {eng_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a32ec8",
   "metadata": {},
   "source": [
    "### Task 7: Select Key Variables for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Life expectancy', 'GDP', 'Schooling', 'Alcohol', 'BMI', 'HIV/AIDS']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7989628",
   "metadata": {},
   "source": [
    "### Task 8: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01899853",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.select_dtypes(include='number').corr(), cmap='coolwarm', annot=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1702068",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='Status', y='Life expectancy', data=df)\n",
    "plt.title('Life Expectancy by Development Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_life = df_final.groupby('Country')['Life expectancy'].mean().sort_values(ascending=False).head(10)\n",
    "avg_life.plot(kind='bar', title='Top 10 Countries by Avg Life Expectancy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ebcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pairplot with hue (e.g., by 'Status' column: 'Developed' or 'Developing')\n",
    "plot = sns.pairplot(\n",
    "    df_final[['Life expectancy', 'HIV/AIDS', 'percentage expenditure', \n",
    "              'Schooling', 'Alcohol', 'Income composition of resources', 'Status']],\n",
    "    hue='Status',                    # Add color grouping by 'Status'\n",
    "    diag_kind='kde',                # KDE for diagonal plots\n",
    "    palette='Set2',                 # Choose a readable color palette\n",
    "    corner=True                     # Optional: show only lower triangle to avoid repetition\n",
    ")\n",
    "\n",
    "# Add a title to the figure\n",
    "plot.fig.suptitle(\"Pairplot of Key Features Grouped by Country Status\", y=1.02, fontsize=16)\n",
    "\n",
    "# Show the legend (usually shown by default with hue, but you can reposition or customize it)\n",
    "plot._legend.set_title(\"Country Status\")  # Custom legend title\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='Status', y='Immunization Score', data=df_final)\n",
    "plt.title(\"Immunization Score by Country Type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c88b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x='Alcohol', y='Life expectancy', hue='Status')\n",
    "plt.title('Life Expectancy vs Alcohol')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d160fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x='Hepatitis B', y='Life expectancy', hue='Status')\n",
    "plt.title('Life Expectancy vs Hepatitis B')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x='HIV/AIDS', y='Life expectancy', hue='Status')\n",
    "plt.title('Life Expectancy vs HIV/AIDS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Plot\n",
    "fig = px.scatter_3d(df, x='GDP', y='Schooling', z='Life expectancy',\n",
    "    color='Status', size='Population')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab515a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_final,\n",
    "    x='GDP',\n",
    "    y='Health Investment',\n",
    "    z='Life expectancy',\n",
    "    color='Status',\n",
    "    hover_name='Country',\n",
    "    size='Population',\n",
    "    title=\"3D Plot: GDP vs Health Investment vs Life Expectancy\")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b0943",
   "metadata": {},
   "source": [
    "### Task 9: Interpretation\n",
    "- Higher GDP and schooling are associated with higher life expectancy.\n",
    "- Developing countries tend to have more outliers and lower average life expectancy.\n",
    "- HIV/AIDS has a strong negative correlation with life expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f7c887",
   "metadata": {},
   "source": [
    "### Task 10: Data Splitting and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final[selected_features + engineered_features]\n",
    " \n",
    "y = df_final['Life expectancy']\n",
    "\n",
    "# Split the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "print(f\"{'Model':<25}{'Train RÂ²':>12}{'Test RÂ²':>12}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    r2_train = r2_score(y_train, model.predict(X_train))\n",
    "    r2_test = r2_score(y_test, model.predict(X_test))\n",
    "    print(f\"{name:<25}{r2_train:>12.4f}{r2_test:>12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656dd37",
   "metadata": {},
   "source": [
    "### Task 11: Cross Validation and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0dc602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Model':<25}{'CV RÂ² (Mean)':>15}{'Std Dev':>12}{'MAE (Mean)':>15}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # RÂ² scores\n",
    "    r2_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    \n",
    "    # MAE scores (note: cross_val_score returns negative MAE)\n",
    "    mae_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    mae_scores = -mae_scores  # Convert to positive\n",
    "\n",
    "    print(f\"{name:<25}{np.mean(r2_scores):>15.4f}{np.std(r2_scores):>12.4f}{np.mean(mae_scores):>15.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc87e60",
   "metadata": {},
   "source": [
    "### Task 12: Conclusion and Recommendations\n",
    "- **Key Findings**: Life expectancy is positively influenced by GDP, schooling, and healthcare access. HIV/AIDS is a major negative predictor.\n",
    "- **Model Performance**: The linear model gives reasonable accuracy with cross-validation.\n",
    "- **Recommendation**: Focus on improving education, economic stability, and healthcare to raise life expectancy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
